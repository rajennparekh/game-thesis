{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bdf22ff",
   "metadata": {},
   "source": [
    "# Play by the Rules: How a Game-Playing GPT Learns\n",
    "\n",
    "### Rajen Parekh and Dr. Yair Shenfeld"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b12804",
   "metadata": {},
   "source": [
    "## 1. Setup Instructions\n",
    "\n",
    "For a fully interactive notebook, clone [my GitHub repository](https://github.com/rajennparekh/game-thesis) and open this notebook. For a PDF version, [INSERT INSTRUCTIONS HERE]. Follow the instructions below to get the notebook ready to run. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc5146b",
   "metadata": {},
   "source": [
    "Open a terminal and run:\n",
    "\n",
    "```bash\n",
    "pip install numpy==2.1.1 ipykernel notebook pandas matplotlib torch ipywidgets\n",
    "```\n",
    "\n",
    "You might need to change `pip` to `pip3`\n",
    "\n",
    "Then, run the cell below, and you’re ready to run and read through the notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfcfb25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from play_against_gpt import play_game\n",
    "from functions_for_thesis_display import display_random_training_run\n",
    "from setup import load_from_checkpoint\n",
    "model = load_from_checkpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12fe8676",
   "metadata": {},
   "source": [
    "## 2. Introduction\n",
    "\n",
    "### Introduction to GPTs\n",
    "\n",
    "In recent years, ChatGPT and other similar large language models have become widespread. Their main goal is to generate coherent and relevant sentences, and they've gotten pretty good at it. But how do these models actually learn and work? There aren’t strict, universal rules of the English language that can be easily programmed and given to the models. Instead, very abstractly, large language models learn by seeing many examples of English text and use these examples to predict the most likely next word in a sentence.\n",
    "\n",
    "So, how can we get a better sense of how large language models learn the task of next word prediction? One approach is to look at a super simple example that does have clear, well-defined rules: tic-tac-toe.\n",
    "\n",
    "### Motivation\n",
    "\n",
    "[Phillip Haeusler](https://philliphaeusler.com/posts/tic_tac_toe/) created and wrote a blog post about Tic Tac Transformer, a GPT model trained to play tic-tac-toe that followed Andrej Karpathy's [NanoGPT](https://www.youtube.com/watch?v=kCc8FmEb1nY) architecture. Of course, this is a terrible way to build a good tic-tac-toe bot. The game is so simple we could just explicitly program the best move in each state. But, we're not really interested in playing tic-tac-toe well. Instead, we can use this model as a tool to learn about large language models. In this setup, a move is like a word, and a game is like a sentence. Just as a sentence is built word by word, a game unfolds move by move—and in both cases, each element depends on what came before it. A string of moves must obey the rules of the game to make sense, just like a sentence must follow grammar and meaning to be coherent. Playing a valid game is analogous to writing a grammatically correct sentence. Playing an optimal game? That’s Shakespeare.<sup>[1]</sup>\n",
    "\n",
    "Tic-tac-toe is especially useful for this kind of exploration because it is interpretable and simple enough that we can analyze the model’s behavior move by move. Because of this simplicity and interpretability, we can use a GPT-style model similar to Tic Tac Transformer trained on tic-tac-toe games to explore three core questions:\n",
    "\n",
    "- Does the model generate novel games, or simply memorize the training data?\n",
    "- How does the model learn over time?\n",
    "- Does it form an internal representation of the game state?\n",
    "\n",
    "The goal of this thesis is to investigate these questions by running a series of experiments and using mechanistic interpretability techniques to analyze the model’s behavior. We introduce each experiment as it becomes relevant throughout the thesis, using them to isolate different aspects of how the model learns and internalizes the structure of the game. Together, these approaches help reveal how a small GPT learns to play, understand, and make sense of a simple game.\n",
    "\n",
    "<p><sup>[1]</sup> <small><em>And something we don't focus on in this project.</em></small></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6674aa2e",
   "metadata": {},
   "source": [
    "## 3. Model Representation, Architecture, and Training\n",
    "Before we start discussing our experiments and results, this section provides a high-level overview of how the model works. We present information on how data is generated and given to the model, the model's architecture, and how the model makes predictions and trains. For a full mathematical description, refer to the appendix.\n",
    "\n",
    "\n",
    "### Tokenization\n",
    "We talked about how tic-tac-toe can be seen as a language with moves as its words, but how do we provide this language to our GPT? Large language models like ChatGPT process language by assigning a unique number to each word in the English language in a process called *tokenization*.<sup>[1]</sup> Each number assigned to a word is a *token*. The model then treats the task of generating words as a classification problem: given a sequence of tokens, what is the most likely next token?\n",
    "\n",
    "<p><sup>[1]</sup> <small><em>Actually, tokenization happens on parts of the English language smaller than words, called subwords. These subwords might be whole words, word stems, or even individual characters, and it also includes numbers, punctuation, and special characters. But, for our purposes, it's simple and accurate enough to think of them as words.</em></small></p>\n",
    "\n",
    "We mirror this setup in tic-tac-toe by assigning a token to each space on the board, and starting our indexing at zero (because it's computer science). The indexing of the spaces is shown below:\n",
    "\n",
    "<img src=\"inserted_images/empty_board_fix.png\" width=250>\n",
    "\n",
    "In addition to the nine board positions, we introduce two special tokens:\n",
    "- `9` is a start token, placed at the beginning of every game.\n",
    "- `10` is a padding token, used to pad the game sequence once the game is over but the board isn’t yet full. Padding allows us to ensure that every game sequence has the same fixed length for training.\n",
    "\n",
    "With these eleven tokens, we can represent every game of tic-tac-toe as a list of 10 tokens. Importantly, the tokens don't specify which players made each move. As humans who know the rules of the game, we know that Player A and Player B alternate moves, but the model sees only the sequence of moves, and must implicitly learn this alternation structure during training.\n",
    "\n",
    "Let's go over an example to clarify. Every game starts with a sequence of `[9]`, and the board looks like the empty board we saw earlier:\n",
    "\n",
    "<img src=\"inserted_images/empty_board_fix.png\" width=250>\n",
    "\n",
    "Then, after a few moves have been played, yielding a sequence of `[9, 6, 4, 2, 8, 0]`, we have a board like this:\n",
    "\n",
    "<img src=\"inserted_images/half_game.png\" width=250>\n",
    "\n",
    "And finally, when the game ends before the board is full, the rest of the sequence is filled with padding tokens. For example, finishing the game above gives the sequence `[9, 6, 4, 2, 8, 0, 3, 1, 10, 10]` and this board:\n",
    "\n",
    "<img src=\"inserted_images/finished_game.png\" width=250>\n",
    "\n",
    "Notice how the sequence length of the completed game is 10, even though the board isn't full? That's because Player A won early, and we used padding tokens to ensure the game sequence was the correct length."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a8a791",
   "metadata": {},
   "source": [
    "### Generation of example games\n",
    "To produce examples of games that our GPT could train and test on, we followed the following procedure to build tokenized games:\n",
    "\n",
    "$$\n",
    "\\begin{array}{ll}\n",
    "\\text{Initialize:} \\\\\n",
    "\\quad \\texttt{game} \\leftarrow [\\texttt{9}] \\quad \\text{(the start token)} \\\\\n",
    "\\quad \\texttt{valid\\_moves} \\leftarrow \\{\\texttt{0}, \\texttt{1}, \\texttt{2}, \\texttt{3}, \\texttt{4}, \\texttt{5}, \\texttt{6}, \\texttt{7}, \\texttt{8}\\} \\\\[1ex]\n",
    "\n",
    "\\text{While the game is not over:} \\\\\n",
    "\\quad \\texttt{move} \\leftarrow \\text{random choice from } \\texttt{valid\\_moves} \\\\\n",
    "\\quad \\texttt{game.append(move)} \\\\\n",
    "\\quad \\texttt{valid\\_moves.remove(move)} \\\\\n",
    "\\quad \\text{Check if there is a winner or the board is full and break loop if so} \\\\[1ex]\n",
    "\n",
    "\\text{Pad the game to length 10:} \\\\\n",
    "\\quad \\text{While } \\texttt{len(game)} < \\texttt{10}: \\\\\n",
    "\\quad\\quad \\texttt{game.append(10)} \\quad \\text{(the padding token)}\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "This results in games between players who play without strategy but always play a valid move. This behavior of randomly selecting a valid move is what we want our GPT to learn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d50c3d",
   "metadata": {},
   "source": [
    "\n",
    "### Model Architecture\n",
    "Our model is based on Karpathy’s NanoGPT, whose architecture is as follows:\n",
    "\n",
    "- An embedding layer, which includes token embeddings (a unique vector learned for each token in the vocabulary) and positional embeddings (a unique vector learned for each position in the input sequence). These two vectors are summed at each position to embed the input sequence into a higher-dimensional space.\n",
    "\n",
    "- A stack of [Transformer blocks](https://arxiv.org/abs/1706.03762), each composed of:\n",
    "  - A LayerNorm, which normalizes the input to stabilize training and improve optimization.\n",
    "  - A causal self-attention mechanism, which allows each token to attend to earlier tokens in the sequence. This helps the model learn and capture interactions between different elements in the sequence.\n",
    "  - A multi-layer perceptron (MLP), which is a feedforward neural network that introduces additional nonlinearity to the outputs of the self-attention layer.\n",
    "  - A residual connection after both the attention and MLP sublayers that adds the input to each sublayer back to its output. This helps preserve information across layers and makes learning easier by allowing the model to make incremental updates rather than relearning everything from scratch.\n",
    "\n",
    "- A final LayerNorm, followed by a linear layer that maps the final hidden states to a probability distribution over our tokens for next-token prediction.\n",
    "\n",
    "For a more precise and technical idea of how the model works, check out the GPT Math section of the appendix.\n",
    "\n",
    "When initializing a GPT, the following parameters can be adjusted:\n",
    "\n",
    "- `n_embd`, the embedding dimension of the embedding layer\n",
    "- `n_head`, the number of attention heads in the self-attention mechanism. This must be a factor of `n_embd`\n",
    "- `n_layer`, the number of transformer blocks in the model\n",
    "\n",
    "We found that the architecture that Haeusler presented (12-dimensional embeddings, 1 attention head, and 1 transformer layer) was the simplest architecture that was able to learn how to play. This architecture is what is used throughout this project unless stated otherwise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd8efc3",
   "metadata": {},
   "source": [
    "### Training the Model\n",
    "How do we train the model? Our GPT is initialized with random weights, but the goal of training is to update these weights so that the model's outputs are as accurate as possible, given the input sequence.\n",
    "\n",
    "We’ve generated a dataset of full games, each represented as a sequence of 10 tokens. However, we want the model to learn to make predictions after any number of moves, not just at the end of the game. So we split each game into many training examples.\n",
    "\n",
    "For example, say we have the full game `[9, 6, 4, 2, 8, 0, 3, 1, 10, 10]` in our training dataset. We can generate multiple prediction tasks from this:\n",
    "\n",
    "- From `[9]`, predict `6`\n",
    "- From `[9, 6, 4]`, predict `2`\n",
    "- From `[9, 6, 4, 2, 8, 0, 3, 1]`, predict `10`\n",
    "\n",
    "The ground truth is always the next token in the sequence. The model is trained by passing in these input sequences, where it predicts probabilities<sup>[1]</sup> for the next token given the input sequence. We compute how accurate its output predictions are and then update the weights to improve performance. We quantify how accurate the model's predictions are by using a loss function called cross-entropy loss, which is calculated as follows:\n",
    "\n",
    "Let $p = (p_0, p_1, \\dots, p_{n})$ be the model’s predicted probability distribution over n tokens.  \n",
    "Let $y \\in \\{0, 1, \\dots, n\\}$ be the index of the correct (target) token.\n",
    "\n",
    "Then the cross-entropy loss is:\n",
    "\n",
    "$$\n",
    "\\mathcal{L} = -\\log(p_y)\n",
    "$$\n",
    "\n",
    "This loss is small when the model assigns high probability to the correct token, and large when it assigns low probability to the correct token. \n",
    "\n",
    "We take the average of the loss function over a batch of examples and use this overall loss to change the model. Then, we use backpropagation to compute the gradient of the loss with respect to each parameter, and use an optimizer to adjust the weights in a direction that reduces the loss. This model uses the AdamW optimizer, which is a slight modification of gradient descent that typically leads to faster and more stable convergence. Unless stated otherwise, we trained the model for 100,000 iterations, where an iteration is defined as one update of the model's weights. Finally, once training is done, we evaluate the model for a final time on an unseen validation dataset.\n",
    "\n",
    "Here’s some pseudocode showing how the training loop works:\n",
    "$$\n",
    "\\begin{array}{ll}\n",
    "\\text{Initialize:} \\\\\n",
    "\\quad \\texttt{model} \\leftarrow \\text{randomly initialized GPT} \\\\\n",
    "\\quad \\texttt{optimizer} \\leftarrow \\text{AdamW optimizer} \\\\\n",
    "\\quad \\texttt{iter} \\leftarrow 0 \\\\[1ex]\n",
    "\n",
    "\\text{Repeat for 100{,}000 iterations:} \\\\\n",
    "\\quad \\texttt{X, Y} \\leftarrow \\text{sample a batch of training examples} \\\\\n",
    "\\quad \\texttt{logits} \\leftarrow \\texttt{model.forward(X)} \\\\\n",
    "\\quad \\texttt{loss} \\leftarrow \\text{cross-entropy between logits and Y} \\\\\n",
    "\\quad \\texttt{compute gradients of loss} \\\\\n",
    "\\quad \\texttt{update model weights using optimizer} \\\\\n",
    "\\quad \\texttt{iter} \\leftarrow \\texttt{iter} + 1 \\\\[1ex]\n",
    "\n",
    "\\text{After training:} \\\\\n",
    "\\quad \\texttt{evaluate model on validation set}\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "<p><sup>[1]</sup> <small><em>Actually, the model outputs logits, which can then be converted to probabilities. I find it easier to think about probabilities than logits, so we'll pretend these are probabilities. The conversion from logits to probabilities is very simple. </em></small></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d17e74",
   "metadata": {},
   "source": [
    "## 4. Answering our Research Questions\n",
    "\n",
    "### Model Success\n",
    "First, let's confirm that the model works. This wouldn't be much of a thesis if it didn't, but test it out below. Keep in mind, the model's goal is to play a legal move, not to play *well*, so you should be able to win pretty easily, but note how it plays by the rules. Click play on the cell below and interact with the buttons to play against the model. *How* does this model learn? Well, that's what we'll discuss in the rest of this document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6e085d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dbcf3fb9c7d4e8ebdc6aef48dd7cffd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(ToggleButtons(description='Who starts:', options=('You go first', 'GPT goes first'), style=Togg…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce5b7e7d6a5c44948a24b342804dd12e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Button(description='⬜', layout=Layout(height='120px', width='120px'), style=Butt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "play_game(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1073bc2",
   "metadata": {},
   "source": [
    "### Model Originality\n",
    "\n",
    "We've seen above that the trained model can successfully play a game of tic-tac-toe. But how does it do that? Might it just be memorizing the games we showed it as it trained, and repeating them back exactly? This would be bad, especially when we think about what it would mean for large language models: what if ChatGPT could only regurgitate exact writing that it had seen before? These models are only useful if they can generate novel games (or text), so we test this capability.\n",
    "\n",
    "To test the model's creativity, we train the model on 100,000 synthetically generated games of tic-tac-toe. These games are created by randomly choosing a move for players until one player wins or the board is filled. After training, we have the model generate 1,000 games and measure how many of them appeared in the training set. Across 100 training trials (60 of which learned to play successfully before 100k iterations, which we'll call the models that \"converged\" later on), the mean originality score was 58.1%.\n",
    "\n",
    "$$\n",
    "\\text{Originality Score} = 1 - \\frac{\\text{\\# of generated games present in training dataset}}{\\text{total \\# of games generated}} = 1 - \\frac{419}{\\text{1000}} = 58.1\\%\n",
    "$$\n",
    "\n",
    "Next, we consider what kind of originality score we should expect. Since there are 255,168 possible games of Tic-Tac-Toe and our synthetic dataset includes 100,000 of them, we’d expect the model’s originality to reflect the proportion of games not seen during training:<sup>[1]</sup>\n",
    "\n",
    "$$\n",
    "\\frac{255,\\!168 - 100,\\!000}{255,\\!168} \\approx 60.8\\%\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67288b02",
   "metadata": {},
   "source": [
    " So, the model is able to generate unseen game sequences at approximately the rate we'd expect.<sup>[2]</sup> It is not memorizing, but instead seems to be learning the rules of the game and generating games it has never seen before. We'll explore how it does that in the following section.\n",
    "\n",
    "\n",
    "<p><sup>[1]</sup> <small><em>We would actually expect an originality score slightly higher than 60.8%, because the synthetic games are randomly generated, and can include overlapping games. A dataset with 100,000 elements is highly unlikely to have 100,000 distinct elements, but this is an expected floor for our originality score.</em></small></p>\n",
    "\n",
    "<p><sup>[2]</sup> <small><em>This value is slightly smaller than the rate we'd expect. I think this is happening because some of the 255,168 games are more likely to occur when creating the synthetic dataset. For example, to match a short game when Player A wins quickly, only five moves need to match, but to match a long game, nine moves need to match. This means the short games are more likely to be generated synthetically (and be in our training data), and are more likely to be generated by any model that selects between moves randomly. This should drive originality scores down. To test this hypothesis, I generated a new dataset of games as described before, effectively simulating a model that chooses valid moves at random. I then treated these as if they were model-generated games and calculated their originality score relative to the original training set. The resulting originality score was 58.8%, nearly identical to the GPT’s. This supports the idea that lower originality scores than expected are a natural consequence of the data distribution, rather than evidence of any memorization.</em></small></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d7b865",
   "metadata": {},
   "source": [
    "### Learning the Rules of the Game\n",
    "What are the rules of tic-tac-toe? Without thinking about any strategy, we can define two things a player needs to do in order to play by the rules:\n",
    "\n",
    "1. Pick a space that neither player has played in before to place their piece. A space can't be occupied by multiple pieces, and if a player tries to play on top of another piece, a mistake has been made.\n",
    "\n",
    "2. A player wins by placing three of their pieces consecutively in any row, column, or diagonal (we'll call this \"three in a row\" from now on, because that is typically how people refer to the game). If the game is over and a player tries to play, or the game is not over and a player states that it is, a mistake has been made.\n",
    "\n",
    "**Keep these rules in mind!** They'll be very important for the rest of this document.\n",
    "\n",
    "Let's take a closer look at the 62 training trials that learned to play successfully to see how these models might be learning the two rules stated above. Plotted below is the validation loss by iteration for each of the trials. The graph is a little messy since there are so many trials shown, but take a look and see if you notice a trend:\n",
    "\n",
    "<!-- <img src=\"inserted_images/converging_runs.png\" width=1000> -->\n",
    "![](inserted_images/converging_runs.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae800639",
   "metadata": {},
   "source": [
    "Notice how many trials stall with a validation loss between 1.36 and 1.37? In fact, >70% of the runs that converge exhibit this stalling behavior for at least 5,000 iterations. Let's take a closer look at them and see what's going on...\n",
    "\n",
    "We'll define two new statistics to measure how well a model understands the rules:\n",
    "1. Invalid Move Rate: This measures how often the model generates a move that has been previously played in the game sequence. It is computed over all generated games (rather than all generated moves), so if a game has any invalid move, it is counted towards the invalid rate. It is calculated as follows:\n",
    "\n",
    "$$\n",
    "\\text{Invalid Move Rate} = \\frac{\\text{\\# of generated games with an occupied space generated}}{\\text{Total \\# of generated games}}\n",
    "$$\n",
    "\n",
    "2. Correct Ending Rate: This measures how often the model predicts that the padding token will be the next token when given a game with a winner. In the training data, whenever a game ends before 9 moves (meaning a player has won before the board is full), the game sequence appends padding tokens to preserve the full sequence length. Once a model learns Rule 2, it should always predict the padding token when given a game completed before 9 moves have been played to mirror this pattern in the training data. It is calculated as follows:\n",
    "\n",
    "$$\n",
    "\\text{Correct Ending Rate} = \\frac{\\text{\\# of correct padding predictions after an early win}}{\\text{\\# of generated games resulting in either player winning early}}\n",
    "$$\n",
    "\n",
    "Run the cell below to randomly select one of the trials that exhibited this stalling behavior. Notice the pattern between the validation loss (rescaled to fit on the same axes), the invalid move rate, and the correct ending rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a190cd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_random_training_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6c3de7",
   "metadata": {},
   "source": [
    "The first thing to note is that, in all of these trials, the correct ending rate approaches 1 and the invalid move rate approaches 0 by the end of training. This means that by the end of training, the model successfully learns the rules of tic-tac-toe! It can avoid playing in occupied spaces and identifies when the game has been won.\n",
    "\n",
    "Next, observe that the validation loss drops in two stages. During the first one, the invalid move rate drops nearly to 0, but the correct ending rate stagnates and/or fluctuates randomly, showing no improvement. Then, during the second drop, the invalid move rate increases slightly while the correct ending rate drastically increases. As training finishes, the correct ending rate gets even higher, and the invalid move rate slowly decreases back towards 0. This trend holds for all of the trials that stall with a loss between 1.36 and 1.37 for at least 5,000 iterations. Keep hitting play on the cell above to randomly select more trials and confirm this trend.\n",
    "\n",
    "Clearly, the model seems to be learning the two rules of tic-tac-toe separately, first learning to play in unoccupied spaces and next learning to identify winners, but what is going on internally when this happens? *How* does this learning occur?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a3e018",
   "metadata": {},
   "source": [
    "### Internal Game Representation\n",
    "\n",
    "#### Background Work\n",
    "A [research team from Harvard, MIT, and Northeastern](https://arxiv.org/abs/2210.13382) created a model called OthelloGPT, which was a GPT trained to generate games of Othello, another simple board game. Like our tic-tac-toe GPT, it was able to generate valid moves with very few errors. This team's central question was whether OthelloGPT had learned an internal representation of the game state without knowledge of the rules of the game.\n",
    "\n",
    "To study this, they drew inspiration from [Alain and Bengio](https://arxiv.org/abs/1610.01644), who introduced the idea of a *probe*: a model trained to predict some task using a different model's activations. The OthelloGPT team created classifier probes and trained them to predict the state of each space on the board (empty, Player A, or Player B) from the model’s internal activations after being given a sequence of moves. For each layer, they created a dataset by pairing the activations at that layer with the board state implied by the input sequence that produced them. This allowed them to evaluate what information about the board was encoded at different depths of the model.\n",
    "\n",
    "They compared probes trained on a randomly initialized model with probes trained on a fully trained model. The tables below show their results. The Randomized row describes the probe's error rate on the randomly initialized model, and the Synthetic row describes the probe's error rate on the fully trained model.<sup>[1]</sup> Each column describes the error rate of probes trained from different layers of OthelloGPT, with further right columns corresponding to later layers. Keep in mind for later that these error rates are not directly comparable to those produced to our model, as Othello and tic-tac-toe are different games, and our model has a less complex architecture than OthelloGPT.\n",
    "\n",
    "<p><sup>[1]</sup> <small><em>They also include a Championship row, which comes from training the model on real games played between skilled players,  not randomly generated games. We can ignore this row. </em></small></p>\n",
    "\n",
    "Here's their data from the linear probe:\n",
    "\n",
    "<img src=\"inserted_images/othello_linear.png\" width=1000>\n",
    "\n",
    "And here's their data from the MLP probe:\n",
    "\n",
    "<img src=\"inserted_images/othello_mlp.png\" width=1000>\n",
    "\n",
    "On the untrained model, both linear and nonlinear probes performed poorly, showing that the probes themselves were not powerful enough to extract board state from random transformations of the input sequence. On the trained model, however, a nonlinear probe was able to recover the full board state with up to 98% accuracy. This is notable because it shows that during training, OthelloGPT developed an internal representation of the game state, *even though it was never explicitly told the rules of the game, and was only asked to predict the next move*. The linear probe, by contrast, still struggled, performing only slightly better on the trained model than on the untrained model. This suggests that the learned representation was  nonlinear.\n",
    "\n",
    "However, [Neel Nanda](https://www.neelnanda.io/mechanistic-interpretability/othello) further investigated the internal game representation of OthelloGPT. Instead of training the probe to classify a space as Player A/Player B/Empty, he modified the task to classify a space as \"Me\"/\"You\"/Empty from the perspective of the model. If the model is making a move for a given player, the pieces placed by that player are \"Me\" spaces, and pieces placed by the other player are \"You\" spaces. With this modified task, he found that a linear probe was able to reconstruct the board state. \n",
    "\n",
    "Here's what this other approach looks like for tic-tac-toe:\n",
    "Say we have input sequence `[9, 2, 5, 3, 4, 0]`. Recall from the model architecture section that 9 is the start token, and the remaining tokens indicate where Player A and Player B place their alternating moves. In a Player A/Player B representation, the board unsurprisingly looks as follows:\n",
    "\n",
    "<img src=\"inserted_images/p1_p2_board_edit.png\" width=250>\n",
    "\n",
    "But, in a Me/You system, the current player is Player B, so Player B's tokens are counted as Me and Player A's are counted as You:\n",
    "\n",
    "<img src=\"inserted_images/me_opp_board.png\" width=250>\n",
    "\n",
    "Now, observe what happens when we add another move to the game, making our input sequence `[9, 2, 5, 3, 4, 0, 7]`. The original moves on the Player A/Player B board are unchanged:\n",
    "\n",
    "<img src=\"inserted_images/p1_p2_board_update_edit.png\" width=250>\n",
    "\n",
    "But, the original moves on the Me/You board have flipped, because the current player is now Player A:\n",
    "\n",
    "<img src=\"inserted_images/me_opp_board_update.png\" width=250>\n",
    "\n",
    "We'll use this modified task later on, so make sure you understand the difference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50596c30",
   "metadata": {},
   "source": [
    "\n",
    "#### Our Questions\n",
    "Based on these two studies of OthelloGPT, we attempt to apply a version of probing to our model. Our main goal is to understand more about the two-stage learning the model exhibits, and to do so, we ask three questions:\n",
    "1. Does our model learn an internal representation of the board state, like OthelloGPT?\n",
    "2. Is this representation linear or nonlinear?\n",
    "3. How does the internal representation change when the model is at different stages of the training process? And specifically, what happens before and after the model stalls with a validation loss in the 1.36-1.37 range?\n",
    "\n",
    "#### Different Tasks to Test\n",
    "To learn more about our model's behavior, we define four tasks to test our probe on. The first two directly mirror Rule 1 and Rule 2 of tic-tac-toe, which we defined earlier. We know that the model learns to follow Rule 1 by the time stalling begins, and learns to follow Rule 2 by the time stalling ends, so these tasks serve primarily as sanity checks. They confirm that the model’s behavior aligns with the rules of the game, but don’t necessarily indicate that it has formed an internal representation of the board.\n",
    "\n",
    "The next two tasks go further. They focus on the identity of the player occupying each space, and allow us to directly compare the classification tasks from the original OthelloGPT paper and Nanda's update. Successful performance here would suggest that the model has developed an internal representation of the board state, one that captures who played where. It's important to remember that we never told the model there were two different players, or even that there was a board with different spaces. All it saw during training was a sequence of tokens, with the goal of predicting the next one. If probes succeed at this task, it suggests that the model might have developed an internal representation of game state purely through training to do next-token prediction.\n",
    "\n",
    "The tasks are defined below:\n",
    "\n",
    "1. **Space Occupancy**: What spaces are occupied?\n",
    "2. **Win Detection**: Has the game been won?\n",
    "3. **A/B Occupancy**: Which player has played in each space, using Player A's vs Player B's space?\n",
    "4. **Me/You Occupancy**: Which player has played in each space, using Me vs You space?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b855aa",
   "metadata": {},
   "source": [
    "#### Different Probe Architectures\n",
    "We also want to be sure that if there are differences in performance between linear and nonlinear probes, this difference is due to the nonlinearity of the internal representation, not just that nonlinear probes have more parameters and are thus more powerful. <sup>[1]</sup> In order to test this, we use three probes: a linear probe, a small MLP, and a large MLP. The number of parameters for each model and task are shown in the table below:\n",
    "\n",
    "|              | Space Occupancy | Win Detection | A/B Occupancy | Me/You Occupancy |\n",
    "|--------------|--------|--------|--------|--------|\n",
    "| Linear       |    351    |    26    |   351     |     351   |\n",
    "| Small MLP    |   507     |     182   |    507    |   507     |\n",
    "| Large MLP    |   1403     |    978    |   1403     |    1403    |\n",
    "\n",
    "For most tasks, the small MLP is closer in number of parameters to the linear model than it is to the large MLP. This means that if we see a large performance gap between the linear model and the small MLP, but a small performance gap between the small MLP and the large MLP, we can probably attribute the difference to an inherently nonlinear representation, not a more complex probe. \n",
    "\n",
    "<p><sup>[1]</sup> <small><em>The size of the linear vs. nonlinear probes is actually not mentioned in the original Othello paper, so this is an important new addition for us to test. </em></small></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c854a60e",
   "metadata": {},
   "source": [
    "\n",
    "#### Results Part 1: Internal Representation Existence and Linearity\n",
    "In order to train the probes on activation-board pairs, we need to train a GPT to generate these pairs. The training run for the GPT used to generate probing data is displayed below. Circled locations are where checkpoints were taken. From left to right, the checkpoints represent key moments in training:\n",
    "\n",
    "- A **Random** model (Checkpoint 1) with weights initialized before any training\n",
    "- The model where **Stalling Begins** (Checkpoint 2), when validation loss first hits 1.37 and stalling behavior begins\n",
    "- The model where **Stalling Ends** (Checkpoint 3), as validation loss reaches 1.36 and stalling behavior ends\n",
    "- The **Fully Trained** model (Checkpoint 4) after 100,000 iterations\n",
    "\n",
    "<img src=\"inserted_images/checkpoint_locs.png\" width=500>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d77be6",
   "metadata": {},
   "source": [
    "\n",
    "To generate data, we begin by loading the trained GPT model at each of the four checkpoints. We use a dataset consisting of full tic-tac-toe games, each encoded as a sequence of tokens as discussed in the Model Representation section. These sequences represent complete games, but we do not feed the entire sequence to the model all at once. Instead, for each game, we create a series of 10 truncated input sequences: the first contains only the start token, the second contains the start token followed by the first move, the third includes the first two moves, and so on, up to the full sequence of 10 tokens. This results in 10 distinct input sequences per game, each representing a partial progression of the game state.\n",
    "\n",
    "Each of these input sequences is fed through the model, and we extract the corresponding internal activations after three layers of the model:\n",
    "1. The **Embedding** layer\n",
    "2. The **Transformer** block\n",
    "3. The final **LayerNorm** after the transformer. \n",
    "\n",
    "These activations become the input features used to train the probing models.\n",
    "\n",
    "The corresponding ground truth labels are derived directly from the input sequences by decoding the tokenized moves to reconstruct the board state at that point in the game. Depending on the specific probing task, the label is either a classification for each of the 9 spaces on the board (e.g., predicting whether a space is X, O, or empty), or a binary label indicating whether the board has a winner. This procedure is repeated independently for each checkpoint, enabling us to compare how the internal representations evolve over the course of training.\n",
    "\n",
    "Once the probing data is generated, we are left with a distinct dataset for each combination of checkpoint and layer: one for the embedding layer, one for the first transformer block, and one for the final LayerNorm layer, at each of the four checkpoints. Each of these datasets is split into a training set of 100,000 examples and a validation set of 20,000 examples. We train a separate probe on the training portion of each dataset and evaluate it on the corresponding validation set. For Space Occupancy, A/B Occupancy, and Me/You occupancy, we compute space accuracy, defined as the percentage of individual board spaces the probe correctly classifies. For Win Detection, we compute board-level accuracy, which measures how often the probe correctly determines whether or not the board contains a winner.\n",
    "\n",
    "Results of this experiment are shown in tables below. In this section, we'll focus on whether there is an internal representation, whether it is linear, and where within the model this representation is learned. The results compare four probes: a linear, a small MLP, and a large MLP using data from the **Fully Trained** Checkpoint and a large MLP using data from the **Random** Checkpoint. Because this is a randomly initialized model, this large MLP probe serves as a baseline of how well the most powerful probe can do using activations from an untrained model. We can compare the other three probes trained on **Fully Trained** data to this baseline to understand how much the GPT's internal representation improves during training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ddd5f8",
   "metadata": {},
   "source": [
    "\n",
    "#### Task 1: Space Occupancy\n",
    "\n",
    "| Probe Type           | Embedding | Transformer | LayerNorm |\n",
    "|----------------------|---------|---------|---------|\n",
    "| Linear               | 0.774   | 0.936   | 0.943   |\n",
    "| Small MLP            | 0.788   | 0.953   | 0.973   |\n",
    "| Large MLP            | 0.788   | 0.977   | 0.988   |\n",
    "| Large MLP (Baseline)| 0.760   | 0.764   | 0.829   |\n",
    "\n",
    "**1. Does the GPT learn Rule 1?**  \n",
    "*Yes*. By the LayerNorm, all three probes trained on the Fully Trained checkpoint greatly outperform the baseline probe. As expected, probes trained on this model are able to identify which spaces are occupied. Since the model learns not to play in occupied spaces, and we can extract that information from its activations, this suggests it encodes this rule as it learns.\n",
    "\n",
    "**2. Where is this rule learned?**  \n",
    "It seems to be mostly learned the transformer layer. This is where we see probe accuracy spike.\n",
    "\n",
    "**3. Is this representation linear?**  \n",
    "*Mostly*. The linear probe is able to make predictions that are nearly as accurate as either of the MLP probes. The nonlinear probes do slightly outperform the linear probe, so the GPT's representation of this rule may contain some mild nonlinearity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1033c9",
   "metadata": {},
   "source": [
    "\n",
    "#### Task 2: Win Detection\n",
    "\n",
    "| Probe Type     | Embedding | Transformer | LayerNorm |\n",
    "|----------------------|---------|---------|---------|\n",
    "| Linear               | 0.924   | 0.919   | 0.954   |\n",
    "| Small MLP            | 0.925   | 0.986   | 0.986   |\n",
    "| Large MLP            | 0.922   | 0.987   | 0.988   |\n",
    "| Large MLP (Baseline)| 0.912   | 0.922   | 0.924   |\n",
    "\n",
    "**1. Does the GPT learn Rule 2?**  \n",
    "*Yes*. By the LayerNorm, all three probes trained on the Fully Trained Checkpoint greatly outperform the baseline probe. As expected, probes trained on this model are able to identify whether a game has a winner. Since the model learns to detect winners, and we can extract that information from its activations, this suggests it encodes this rule as it learns.\n",
    "\n",
    "**2. Where is this rule learned?**  \n",
    "The MLP probes learn this rule by the transformer layer. However, the linear probe only achieves accuracy above baseline at the LayerNorm.\n",
    "\n",
    "**3. Is this representation linear?**  \n",
    "*Somewhat*. The MLP probes perform similarly to each other, and far outperform the linear probe, but the linear probe does substantially outperform the baseline probe. The fact that the MLP probes learn the internal represenation before Layer 3, while the linear probe does not, suggests that the GPT's LayerNorm removes some, but not all, of the nonlinearity of the representation. This could explain why the linear probe performs better after the LayerNorm than after the transformer block.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f1a622",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### Task 3: A/B Occupancy\n",
    "| Probe Type        | Embedding | Transformer | LayerNorm |\n",
    "|----------------------|---------|---------|---------|\n",
    "| Linear               | 0.609   | 0.729   | 0.732   |\n",
    "| Small MLP            | 0.620   | 0.783   | 0.778   |\n",
    "| Large MLP            | 0.665   | 0.796   | 0.798   |\n",
    "| Large MLP (Baseline)| 0.663   | 0.674   | 0.698   |\n",
    "\n",
    "**1. Is there an internal representation?**  \n",
    "*Yes*. By the LayerNorm, both MLP probes trained on the Fully Trained Checkpoint greatly outperform the baseline probe, and the linear probe slightly outperforms baseline. This suggests the GPT learns some internal representation of space occupancy from a Player A-Player B perspective.\n",
    "\n",
    "**2. Where is this representation learned?**  \n",
    "All three probes learn this representation by the transformer layer. The LayerNorm does not further increase probe accuracy.\n",
    "\n",
    "**3. Is this representation linear?**  \n",
    "*No*. The MLP probes perform similarly to each other, and far outperform the linear probe. The linear probe does perform better than baseline, but not substantially so."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ab4559",
   "metadata": {},
   "source": [
    "\n",
    "#### Task 4: Me/You Occupancy\n",
    "\n",
    "| Probe Type          | Embedding | Transformer | LayerNorm |\n",
    "|----------------------|---------|---------|---------|\n",
    "| Linear               | 0.642   | 0.768   | 0.833   |\n",
    "| Small MLP            | 0.668   | 0.877   | 0.871   |\n",
    "| Large MLP            | 0.670   | 0.900   | 0.901   |\n",
    "| Large MLP (Baseline)| 0.667   | 0.637   | 0.697   |\n",
    "\n",
    "**1. Is there an internal representation?**  \n",
    "*Yes*. By the LayerNorm, all three probes trained on the Fully Trained Checkpoint greatly outperform the baseline probe. This suggests the GPT learns an internal representation of space occupancy from a me-you perspective.\n",
    "\n",
    "**2. Where is this representation learned?**  \n",
    "The MLP probes learn this representation by the transformer layer. The linear probe achieves accuracy over baseline by the transformer layer, but is substantially more accurate after the LayerNorm.\n",
    "\n",
    "**3. Is this representation linear?**  \n",
    "*Somewhat*. The MLP probes perform similarly to each other, and far outperform the linear probe. The linear model does, however, perform substantially better than baseline. The increase in the linear probe's performance between Layer 2 and Layer 3 suggests that the GPT's LayerNorm removes some nonlinearity from its internal representation, making it more accessible to linear probes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac01439",
   "metadata": {},
   "source": [
    "#### Overall summary\n",
    "The success of the probes suggests the GPT model develops internal representations, even though it was not explicitly trained to do so. These representations are largely formed in the transformer layer, with the LayerNorm layer sometimes refining them and making them more accessible to linear probes. For all occupancy tasks, we see a noticeable spike in accuracy for all probe types at the transformer layer, indicating that it encodes relevant information. For Win Detection and A/B occupancy, the LayerNorm layer further boosts linear probe performance, suggesting that it helps transform these nonlinear representations that the transformer produces into a more linearly decodable form.  While linear probes consistently outperform the baseline, they are typically outperformed by both the small and large MLP probes. This pattern, observed across all tasks, suggests that the internal representations are only partially linear.\n",
    "\n",
    "For the two rule-based tasks (Space Occupancy and Win Detection), strong probe performance was expected, as the GPT eventually learned to play by these two rules. We observed this expected strong probe performance, aligning with the low invalid move rate and high correct ending rate we observed in the previous section and confirming that the model has learned to behave according to the rules of tic-tac-toe. \n",
    "\n",
    "In the two player-identity tasks (A/B Occupancy and Me/You Occupancy), probe performance provides strong evidence of an internal representation of board state. These tasks require our probes to use model activations to infer not just what moves have been made, but who made them. This information that was never explicitly provided during training, nor was it a given task for the GPT to learn a representation. However, performance well above   baseline probes suggests that during training, the GPT develops an internal representation of the game to help with next-token prediction.\n",
    "\n",
    "A/B occupancy and Me/You occupancy also mirror the tasks tested by the OthelloGPT team and Nanda, respectively. Consistent with Nanda's work, all probe types perform better on the Me/You task than on the A/B task. This supports the idea that the model interprets and represents the board from the perspective of the *current player*. However, our results diverge from Nanda’s in a key way: while Nanda concluded that A/B occupancy could be fully represented with a linear probe, we find that the nonlinear probes still substantially outperform the linear probe in this setting. This indicates that the GPT's internal representation of the Me/You task is still meaningfully nonlinear. This result aligns more closely with conclusions from the OthelloGPT team, who found that nonlinear probes are needed to access the model’s internal board state representations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c8f67d",
   "metadata": {},
   "source": [
    "\n",
    "#### Results Part 2: Changes in Internal Representation During Training\n",
    "Now that we know that the GPT eventually learns an internal representation of the game state, we'll explore how this representation develops as the model trains. Recall the two rules we defined for tic-tac-toe. In particular, we observed that the GPT first learns to not play in occupied spaces (Rule 1) at the Stalling Begins checkpoint, and later learns to correctly identify the end of games (Rule 2) at the Stalling Ends checkpoint. These changes in behavior are expected, but do they correspond to actual shifts in the model’s internal representations? How do the internal representations change during training?\n",
    "\n",
    "We test this by comparing the performance of each probe type (Linear, Small MLP, Large MLP) on our four tasks across checkpoints. Space Occupancy explicitly tests model understanding of Rule 1, and Win Detection explicitly tests model understanding of Rule 2. A/B Occupancy and Me/You Occupancy involve understanding and representing the entire board state, so they provide a more complete test of whether and how the model internalizes the structure of the game.\n",
    "\n",
    "Presented below are tables for the accuracies of probes trained on each checkpoint from activations taken from the LayerNorm of the GPT, as well as a chart showing how each probe's performance changes across checkpoints. We'll discuss the results below.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d897d96",
   "metadata": {},
   "source": [
    "\n",
    "#### Linear Probe\n",
    "\n",
    "| Task     | Random | Stalling Begins | Stalling Ends | Fully Trained |\n",
    "|----------|--------------|--------------|--------------|--------------|\n",
    "| Space Occupancy   | 0.660        | 0.948        | 0.932        | 0.943        |\n",
    "| Win Detection   | 0.900        | 0.920        | 0.954        | 0.954        |\n",
    "| A/B Occupancy   | 0.569        | 0.745        | 0.734        | 0.732        |\n",
    "| Me/You Occupancy  | 0.587        | 0.750        | 0.824        | 0.833        |\n",
    "\n",
    "#### Small MLP Probe\n",
    "\n",
    "| Task     | Random | Stalling Begins | Stalling Ends | Fully Trained |\n",
    "|----------|--------------|--------------|--------------|--------------|\n",
    "| Space Occupancy   | 0.790        | 0.979        | 0.960        | 0.973        |\n",
    "| Win Detection    | 0.923        | 0.921        | 0.987        | 0.986        |\n",
    "| A/B Occupancy    | 0.649        | 0.769        | 0.755        | 0.778        |\n",
    "| Me/You Occupancy   | 0.661        | 0.772        | 0.855        | 0.871        |\n",
    "\n",
    "#### Large MLP Probe\n",
    "\n",
    "| Task     | Random | Stalling Begins | Stalling Ends | Fully Trained |\n",
    "|----------|--------------|--------------|--------------|--------------|\n",
    "| Space Occupancy   | 0.829        | 0.991        | 0.970        | 0.988        |\n",
    "| Win Detection    | 0.924        | 0.922        | 0.988        | 0.988        |\n",
    "| A/B Occupancy    | 0.698        | 0.779        | 0.778        | 0.798        |\n",
    "| Me/You Occupancy   | 0.697        | 0.792        | 0.879        | 0.901        |\n",
    "\n",
    "#### Results Plotted\n",
    "\n",
    "\n",
    "<img src=\"inserted_images/labeled_accuracy_by_checkpoint_key.png\" width=1000>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6f7482",
   "metadata": {},
   "source": [
    "\n",
    "#### Observations\n",
    "\n",
    "Take a look at the tables and chart above, and focus on the transition between Stalling Begins and Stalling Ends. As we discussed, this is where the GPT's behavior shifts. At the Stalling Begins checkpoint, the model has learned not to play invalid moves but cannot identify when the game has ended (invalid move rate is low, but correct ending rate is also low), but at the Stalling Ends checkpoint, it learns to identify when games have ended (the correct ending rate is now high) . This progression aligns with our two defined rules of tic-tac-toe. Space Occupancy (Rule 1) and Win Detection (Rule 2) help isolate the internal representation of each rule, while A/B Occupancy and Me/You Occupancy depend on a composition of both.\n",
    "\n",
    "By the Stalling Begins checkpoint, Space Occupancy performance is already nearly perfect for all probe types, especially for the nonlinear probes. This is expected, since the GPT plays according to Rule 1 by this point, but the probe performance confirms that the rule is also internally represented. In contrast, performance on Win Detection does not improve until the Stalling Ends checkpoint, where it jumps to nearly perfect performance, especially for the MLP probes. This shift in Win Detection accuracy mirrors the point at which the GPT starts identifying game ends correctly, suggesting that the internal representation of Rule 2 is not present until this later checkpoint.\n",
    "\n",
    "A/B and Me/You Occupancy both require an understanding of both Rule 1 and Rule 2, but they show different patterns. Probes trained on A/B Occupancy see a jump from the Random checkpoint to the Stalling Begins checkpoint, then plateau, while Me/You Occupancy probes show steady improvement throughout training. We see jumps in Me/You Occupancy performance as each rule is learned, suggesting that as the model learns how to play, it also learns to internally represent the board. Notably, all probe types perform better on Me/You Occupancy than A/B Occupancy, supporting the idea that the GPT internally understands the game through this lens.\n",
    "\n",
    "Taken together, these results highlight that the GPT's internal representation of game state evolves in distinct phases. First, it learns to represent Space Occupancy (Rule 1) by the Stalling Begins checkpoint, then it learns to represent Win Detection (Rule 2) by the Stalling Ends checkpoint. As these rule representations improve, so does probe accuracy on Me/You Occupancy. This suggests that learning the rules improves not just the model’s behavior, but also its internal representation of the game state. Importantly, the probes help us understand not just *that* the model behaves differently, but *why* it performs differently, by revealing when different understandings of the board state become represented internally by the model. The probing tasks allow us to track these representational changes during training, and the difference in Me/You occupancy probe performance before and after stalling behavior offers strong evidence that the changes in model behavior we observed reflect changes in the model’s internal encoding of the game. While the model could in theory behave correctly without any internal representation of the game, the probes show that such a representation does, in fact, emerge and evolve over training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce09b24",
   "metadata": {},
   "source": [
    "## 5. Conclusion\n",
    "\n",
    "### Summary of Findings\n",
    "In this project, we trained a GPT to generate valid moves and complete games of tic-tac-toe. We were interested in three main questions:\n",
    "\n",
    "1. Does the model generate novel games, or just memorize games that it was shown?\n",
    "2. How does this learning occur?\n",
    "3. Is there an internal representation of the game? Does it change as the model learns?\n",
    "\n",
    "To answer the first question, we looked at the full games the model generated and observed what proportion of those were included in the training dataset, and what proportion were original. We found that the model generated original games at around the frequency we'd expect of a model without any memorization, so we concluded that the model was not memorizing, but instead was learning to play tic-tac-toe legally.\n",
    "\n",
    "To address the second question, we tracked how the model learned over time. In more than 70% of successful training runs, the model's loss decreases in two distinct stages. Each of these stages corresponds to one of the two rules of tic-tac-toe:\n",
    "1. Play a piece in an unoccupied space.\n",
    "2. If one player places three of their pieces in a row, they win.\n",
    " \n",
    "After the first stage, the model learns to avoid illegal moves where it attempts to play in an already-occupied space (Rule 1). After the second stage, the model learns to recognize when a player has won by occupying three spaces in a row and stops predicting additional moves, instead predicting the padding token used to signify the end of a game (Rule 2). These shifts in behavior suggest that the model somehow internalizes the basic rules of tic-tac-toe, first learning how to play legally, then learning how the game ends.\n",
    "\n",
    "For our final question, we were interested in understanding more about how the model learns the rules of the game. To do so, we trained linear and nonlinear probes on the GPT's activations to see if the GPT developed an internal representation of the board state, and if this representation changed throughout training. We defined four probing tasks: Space Occupancy and Win Detection reflected the rules of tic-tac-toe we defined earlier. A/B Occupancy and Me/You Occupancy involved identifying which player occupied each square (with different framing) and tested understanding of the entire board. While the first two tasks helped confirm that the model was behaving according to the rules, the second two were more reflective of whether the model had developed a full internal representation of game state. For each of these tasks, probes trained on activations from a fully trained GPT outperformed probes trained on activations from an untrained GPT, suggesting that the GPT learned an internal representation of the board. Importantly, the model was not tasked with learning this internal representation, only generating the next valid move, but the representation developed anyway. We tracked the success of the probes across layers and found that this representation was primarily learned by the transformer layer. Because nonlinear probes consistently outperformed linear probes, it seems that this representation is somewhat nonlinear. Improvement in linear probes after the final LayerNorm suggests that this layer removes some nonlinearity from the model's internal representations. Finally, we observed that the internal representation evolved as the GPT trained, and the game state information our probes were able to extract matched the model's generation capabilities at the training stage from which the probe was trained.\n",
    "\n",
    "Tic-tac-toe isn't exactly language generation, but we studied our GPT using techniques that are often used in mechanistic interpretability research on LLMs like ChatGPT. We tested for model originality and memorization, tracked different metrics for learning as the model trained, and introduced probes to investigate how the model internalized its understanding of the game. Of course, GPTs trained on natural language are vastly more complex models trying to learn a much more ambiguous task. They don’t have explicit rules like tic-tac-toe, and their internal representations are shaped by more varied objectives and data. Still, we can apply a similar sort of study: by training a model on next-token prediction, we can begin to uncover how the architecture supports generalization, rule learning, and internal representation. This project shows that even tiny GPTs, trained on simple data, can develop accurate internal representations. These toy models offer an environment where we can test hypotheses, develop tools, and build intuition that may eventually scale to more complex work."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9aa849",
   "metadata": {},
   "source": [
    "\n",
    "### Future Work\n",
    "\n",
    "While I'm satisfied with my findings in this project, there were a number of tasks/questions I wanted to look into, but didn't have the time to accomplish. I've detailed some avenues for future work below:\n",
    "\n",
    "#### Generalization to *mnk* Games\n",
    "Tic-tac-toe is a special case of an *mnk* game (with *m* = *n* = *k* = 3), where players alternate turns on an *m* × *n* board and aim to control *k* consecutive spaces. A natural extension of this project is to explore how the GPT learns to play these [more complicated](https://www.sciencedirect.com/science/article/pii/S0304397520301146) games. I was planning to go in this direction for a while before I noticed the multi-stage learning and decided to investigate that, so my codebase is set up to work with all *mnk* games. Because of that work, it shouldn't be too difficult to extend this project to more general *mnk* cases.\n",
    "\n",
    "#### Minimum Embedding Dimensionality\n",
    "As I tested different GPT architecture, I found that a minimum of 12-dimensional embeddings were necessary for the GPT to learn to play legal games. This mirrors what Haeusler found in his original creation of TicTacTransformer. However, neither Haeusler nor I propose *why* 12 dimensions might be necessary. This result is especially surprising because, in theory, 11 dimensions should be sufficient to uniquely represent each token given that our vocabulary is only 11 words (all nine moves on the board, the start token, and the pad token). Further investigation to discover why 12-dimensional embeddings are necessary could help us further understand the model's learning process.\n",
    "\n",
    "#### Interventions on Internal Representations\n",
    "In addition to training probes on their model's activations, OthelloGPT team demonstrated that it is possible to causally intervene on a model’s internal representations to manipulate its behavior in predictable ways. In their experiments, they passed in a game sequence to OthelloGPT, then edited the model's activations so that their probes would predict a different board state from the one that was inputted. Using these new activations, the model was told to predict the next move. They found that the model predicted moves that were legal on the new board state inferred from the probe, not the original board state given to the model. This showed that the model’s internal representation of game state was not a byproduct of training, but instead was influential in shaping its output. \n",
    "\n",
    "A clear next step for this project is to perform similar interventions on our GPT. By editing the model's activations so that our probes predicted a different board state, we could test whether the model's predictions change in response. For example, if we change the activations such that a previously occupied space appears empty, and the model then chooses to place a move there, it would suggest that the model relies on its internal board representation to decide where to play. This kind of intervention would help us figure out whether the internal representations we saw with probes are actually used by the model to guide its predictions, or if they’re just a side effect of training that happen to be decodable by our probes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a052d4b6",
   "metadata": {},
   "source": [
    "## 6. Acknowldegements\n",
    "\n",
    "First, I want to thank Dr. Yair Shenfeld, my Honors Thesis advisor. He has been incredibly helpful throughout this year, giving me advice, thinking through my experiments with me, and providing important feedback along the way. I wouldn't have been able to research nearly as much, or nearly as well, without him. I also want to thank Dr. Ritambhara Singh, my second reader, for her help and teaching. Her CSCI 2952G class was my first introduction to interpretability techniques in deep learning, and the content that I learned helped inspire parts of this project.\n",
    "\n",
    "More generally, this thesis is somewhat of a culmination of my time and academic work at Brown. I want to thank my friends here for all of the time they spent with me throughout this entire process (and over our four years here), and my family for all of their support and encouragement along the way."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1905b69",
   "metadata": {},
   "source": [
    "## 7. Appendix\n",
    "Presented here is the math of how a GPT works, as well as a couple of experiments I ran that didn't fit in exactly with the project I wanted to present.\n",
    "\n",
    "### 1. GPT Math\n",
    "#### Model Initialization and Configuration\n",
    "\n",
    "The model is instantiated with a configuration that specifies the following parameters:\n",
    "\n",
    "- **`block_size (BLOCK_SIZE)`**: the maximum number of tokens the model can process.  \n",
    "- **`vocab_size (VOCAB_SIZE)`**: the size of the vocabulary, representing all possible moves plus special tokens.  \n",
    "- **`n_layer (LAYER_COUNT)`**: the number of Transformer layers in the model.  \n",
    "- **`n_head (HEAD_COUNT)`**: the number of attention heads in each Transformer layer.  \n",
    "- **`n_embd (N_EMBD)`**: the dimensionality of the token and position embeddings.  \n",
    "- **`mlp_mult (MLP_MULT)`**: a scalar multiplier controlling the hidden size of the MLP layers.  \n",
    "\n",
    "The model is instantiated with a configuration that specifies the following parameters:\n",
    "\n",
    "We adopt the following indexing convention:  \n",
    "- Capitalized names (`N_EMBD`, `VOCAB_SIZE`, etc.) denote tensor dimensions.  \n",
    "- Lowercase letters of the same name (`n`, `v`, etc.) are used for indexing over those dimensions in pseudocode and equations.\n",
    "- We use 1-indexing in the mathematical notation\n",
    "\n",
    "All weight matrices are initialized randomly from a normal distribution \n",
    "$$\n",
    "\\mathcal{N}\\left(0, \\frac{0.02}{\\sqrt{2 \\cdot \\texttt{n\\_layer}}} \\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1651b144",
   "metadata": {},
   "source": [
    "#### Token Embeddings\n",
    "\n",
    "To access token embeddings, the model uses a weight matrix `W_e` with dimensions `(VOCAB_SIZE, N_EMBD)`, where each row `W_e[i]` contains the embedding for the *i*-th item in the vocabulary.\n",
    "\n",
    "Given an input sequence `x` of token indices with shape `(TOKEN_COUNT)`<sup>[1]</sup>, each token is mapped to its corresponding embedding from `W_e`. This produces a token embedding matrix `tok_emb` with dimensions `(T, N_EMBD)`, where each element `tok_emb[t, n]` is obtained by mapping token `t` to its embedding vector `W_e[t]`, which has size `N_EMBD`.\n",
    "\n",
    "```python\n",
    "# Algorithm: Token Embedding Calculation\n",
    "for each position t in sequence length TOKEN_COUNT:\n",
    "    tok_emb_t ← W_e[x_t]  # Retrieve embedding for token x_t\n",
    "```\n",
    "<p><sup>[1]</sup> <small><em><code>TOKEN_COUNT</code> refers to the number of tokens in the input sequence <code>x</code>, not the total vocabulary size. We always have <code>TOKEN_COUNT ≤ block_size</code> because <code>block_size</code> is the maximum input size the model will take.</em></small></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2febe5df",
   "metadata": {},
   "source": [
    "#### Position Embeddings\n",
    "\n",
    "In addition to token embeddings, positional information is added to indicate each token’s position within the sequence. This is achieved through a position embedding matrix `W_p` with dimensions `(BLOCK_SIZE, N_EMBD)`, where each row `W_p[i]` represents the embedding for position *i*.\n",
    "\n",
    "For a given sequence of length `TOKEN_COUNT`, we retrieve one position embedding for each token position. This produces a position embedding matrix `pos_emb` of shape `(TOKEN_COUNT, N_EMB)`.\n",
    "\n",
    "```python\n",
    "# Algorithm: Position Embedding Calculation\n",
    "for each position t in sequence length TOKEN_COUNT:\n",
    "    pos_emb_t ← W_p[t]  # Retrieve position embedding for position t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098d3350",
   "metadata": {},
   "source": [
    "#### Combined Embeddings\n",
    "\n",
    "The full embedding matrix for the input sequence is created by summing the token and position embeddings:\n",
    "\n",
    "$$\n",
    "\\texttt{emb}[t, n] = \\texttt{tok\\_emb}[t, n] + \\texttt{pos\\_emb}[t, n]\n",
    "$$\n",
    "\n",
    "where `emb[t, n]` represents the combined embedding at position `t` and embedding dimension `n`.\n",
    "\n",
    "```python\n",
    "# Algorithm: Combined Embedding Calculation\n",
    "for each token position t in sequence length TOKEN_COUNT:\n",
    "    for each embedding dimension n in range(N_EMBD):\n",
    "        emb[t, n] ← tok_emb[t, n] + pos_emb[t, n]  # Sum token and position embeddings\n",
    "```\n",
    "\n",
    "The overall embedding matrix has shape `(TOKEN_COUNT, N_EMBD)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8393d260",
   "metadata": {},
   "source": [
    "#### Layer Normalization\n",
    "\n",
    "Layer normalization is applied to stabilize training by normalizing across the embedding dimension at each token position. The input to LayerNorm has shape `(TOKEN_COUNT, N_EMBD)`.\n",
    "\n",
    "For an input `x` of shape `(TOKEN_COUNT, N_EMBD)`, we compute the mean and variance across the embedding dimension for each position `t`:\n",
    "\n",
    "$$\n",
    "\\mu_t = \\frac{1}{N\\_EMBD} \\sum_{n=1}^{N\\_EMBD} \\texttt{x}[t, n]\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\sigma^2_t = \\frac{1}{N\\_EMBD} \\sum_{n=1}^{N\\_EMBD} (\\texttt{x}[t, n] - \\mu_t)^2\n",
    "$$\n",
    "\n",
    "We normalize each embedding value:\n",
    "\n",
    "$$\n",
    "\\hat{\\texttt{x}}[t, n] = \\frac{\\texttt{x}[t, n] - \\mu_t}{\\sqrt{\\sigma^2_t + \\epsilon}}\n",
    "$$\n",
    "\n",
    "where $\\epsilon$ is a small constant to prevent division by zero.\n",
    "\n",
    "Finally, we apply learnable scale and shift parameters `gamma` and `beta`, each of shape `(N_EMBD)`:\n",
    "\n",
    "$$\n",
    "\\texttt{normalized\\_result}[t, n] = \\texttt{gamma}[n] \\cdot \\hat{\\texttt{x}}[t, n] + \\texttt{beta}[n]\n",
    "$$\n",
    "\n",
    "The output `normalized_result` has the same shape as the input: `(TOKEN_COUNT, N_EMBD)`.\n",
    "\n",
    "```python\n",
    "# Algorithm: Layer Normalization\n",
    "for each token position t in sequence length TOKEN_COUNT:\n",
    "    mu_t ← mean over n of x[t, n]\n",
    "    var_t ← mean over n of (x[t, n] - mu_t)²\n",
    "    for each embedding dimension n in range(N_EMBD):\n",
    "        x_hat[t, n] ← (x[t, n] - mu_t) / sqrt(var_t + epsilon)\n",
    "        normalized_result[t, n] ← gamma[n] * x_hat[t, n] + beta[n]\n",
    "```\n",
    "\n",
    "\n",
    "We apply <code>LayerNorm</code> to <code>emb</code> to produce <code>normalized_emb</code>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f10f54",
   "metadata": {},
   "source": [
    "#### Causal Self-Attention\n",
    "\n",
    "The next part of the Transformer block is Causal Self-Attention, which takes an input `normalized_emb` of shape `(TOKEN_COUNT, N_EMBD)`.\n",
    "\n",
    "We apply a linear layer with weight matrix `W_qkv` of shape `(3 × N_EMBD, N_EMBD)` to compute concatenated query, key, and value vectors. For each element `qkv[t, n]`, we compute:\n",
    "\n",
    "$$\n",
    "qkv[t, n] = \\sum_{m=1}^{N\\_EMBD} \\texttt{W\\_qkv}[n, m] \\cdot \\texttt{normalized\\_emb}[t, m]\n",
    "$$\n",
    "\n",
    "This produces a tensor of shape `(TOKEN_COUNT, 3 × N_EMBD)`, which we split into three separate tensors: query `q`, key `k`, and value `v`, each of shape `(TOKEN_COUNT, N_EMBD)`.\n",
    "\n",
    "We then reshape `q`, `k`, and `v` from shape `(TOKEN_COUNT, N_EMBD)` to `(TOKEN_COUNT, HEAD_COUNT, DIM_PER_HEAD)`, where `DIM_PER_HEAD = N_EMBD / HEAD_COUNT`.\n",
    "\n",
    "For a given index `n`, we interpret it as a combination of two indices:\n",
    "- `h = floor(n // DIM_PER_HEAD)` — the head index\n",
    "- `d = n % DIM_PER_HEAD` — the position within the head\n",
    "\n",
    "To do so, for each tensor `m` in `{q, k, v}`, we define a new view `m_reshaped` with shape `(TOKEN_COUNT, HEAD_COUNT, DIM_PER_HEAD)` such that:\n",
    "\n",
    "$$\n",
    "\\texttt{m\\_reshaped}[t, h, d] = \\texttt{m}[t, h \\cdot DIM\\_PER\\_HEAD + d]\n",
    "$$\n",
    "\n",
    "We then transpose to move the head dimension first, resulting in shape `(HEAD_COUNT, TOKEN_COUNT, DIM_PER_HEAD)`:\n",
    "\n",
    "$$\n",
    "\\texttt{m\\_transposed}[h, t, d] = \\texttt{m\\_reshaped}[t, h, d]\n",
    "$$\n",
    "\n",
    "Next, we calculate the attention weights by performing a scaled dot product between `q` and `k`:\n",
    "\n",
    "$$\n",
    "\\texttt{attn\\_weight}[h, t, j] = \\frac{1}{\\sqrt{\\texttt{DIM\\_PER\\_HEAD}}} \\sum_{d=1}^{\\texttt{DIM\\_PER\\_HEAD}} q[h, t, d] \\cdot k[h, j, d]\n",
    "$$\n",
    "To enforce the causal structure, ensuring the model can only attend to previous or current tokens, we apply an attention mask. This is a matrix `mask[t, j]` of shape `(TOKEN_COUNT, TOKEN_COUNT)`, where:\n",
    "\n",
    "- `mask[t, j] = 0` if `j ≤ t` (token `j` is visible to token `t`)\n",
    "- `mask[t, j] = −∞` if `j > t` (token `j` is in the future)\n",
    "\n",
    "We then define the attention bias matrix as:\n",
    "\n",
    "$$\n",
    "\\texttt{attn\\_bias}[t, j] = \\texttt{mask}[t, j]\n",
    "$$\n",
    "\n",
    "and add it to the raw attention scores:\n",
    "\n",
    "$$\n",
    "\\texttt{attn\\_weight}[h, t, j] \\leftarrow \\texttt{attn\\_weight}[h, t, j] + \\texttt{attn\\_bias}[t, j]\n",
    "$$\n",
    "\n",
    "This ensures that any scores corresponding to future tokens (where \\( j > t \\)) are set to \\( -\\infty \\), effectively masking them out during the next step. As a result, the model cannot attend to future positions in the sequence. This causal masking is essential for the task of next-token prediction: at each step, the model is only allowed to use information from the current and previous tokens and cannot look ahead at the next token or any tokens beyond it.\n",
    "\n",
    "We now convert these masked attention weights into a probability distribution using the softmax function. The softmax function is defined as:\n",
    "\n",
    "$$\n",
    "\\texttt{softmax}(z_i) = \\frac{\\exp(z_i)}{\\sum_j \\exp(z_j)}\n",
    "$$\n",
    "\n",
    "It ensures that all output values are non-negative and sum to 1, making it suitable for interpreting scores as probabilities. Applied to our attention weights:\n",
    "\n",
    "$$\n",
    "\\texttt{attn\\_weight}[h, t, j] = \\frac{\\exp(\\texttt{attn\\_weight}[h, t, j])}{\\sum_{j'=1}^{\\texttt{TOKEN\\_COUNT}} \\exp(\\texttt{attn\\_weight}[h, t, j'])}\n",
    "$$\n",
    "\n",
    "Then, we compute a weighted sum of the value tensor:\n",
    "\n",
    "$$\n",
    "\\texttt{attn\\_output}[h, t, d] = \\sum_{j=1}^{\\texttt{TOKEN\\_COUNT}} \\texttt{attn\\_weight}[h, t, j] \\cdot v[h, j, d]\n",
    "$$\n",
    "\n",
    "This gives a tensor of shape `(HEAD_COUNT, TOKEN_COUNT, DIM_PER_HEAD)`. We transpose to move the head dimension first, resulting in shape `(TOKEN_COUNT, HEAD_COUNT, DIM_PER_HEAD)`:\n",
    "\n",
    "$$\n",
    "\\texttt{attn\\_output\\_reshaped}[t, h, d] = \\texttt{attn\\_output}[h, t, d]\n",
    "$$\n",
    "\n",
    "We next reshape `attn_output_reshaped` from shape `(TOKEN_COUNT, HEAD_COUNT, DIM_PER_HEAD)` back to `(TOKEN_COUNT, N_EMBD)`, where `N_EMBD = HEAD_COUNT × DIM_PER_HEAD`.\n",
    "\n",
    "As defined above, we represent each embedding index `n` as a combination of two indices:\n",
    "- `h = floor(n // DIM_PER_HEAD)` — the head index\n",
    "- `d = n % DIM_PER_HEAD` — the position within the head\n",
    "\n",
    "To do so, we define a new view `attn_output_merged` of shape `(TOKEN_COUNT, N_EMBD)` such that:\n",
    "\n",
    "$$\n",
    "\\texttt{attn\\_output\\_merged}[t, n] = \\texttt{attn\\_output\\_reshaped}[t, h, d]\n",
    "$$\n",
    "\n",
    "This gives us the combined output of all heads in a single embedding dimension.\n",
    "\n",
    "\n",
    "Next, we apply a linear projection with weight matrix `W_c_proj` of shape `(N_EMBD, N_EMBD)` to merge the output of the heads:\n",
    "\n",
    "$$\n",
    "\\texttt{attn\\_proj}[t, n] = \\sum_{m=1}^{N\\_EMBD} \\texttt{W\\_c\\_proj}[n, m] \\cdot \\texttt{attn\\_output}[t, m]\n",
    "$$\n",
    "This linear layer allows the model to learn to combine information from all heads, rather than relying on simple concatenation.\n",
    "\n",
    "Finally, we add a residual connection by summing the attention output with the original input:\n",
    "\n",
    "$$\n",
    "\\texttt{self\\_attention\\_activations}[t, n] = \\texttt{normalized\\_emb}[t, n] + \\texttt{attn\\_proj}[t, n]\n",
    "$$\n",
    "\n",
    "This produces the final output of the self-attention layer with shape `(TOKEN_COUNT, N_EMBD)`.\n",
    "\n",
    "```python\n",
    "# Algorithm: Causal Self-Attention\n",
    "# Input: normalized_emb of shape (TOKEN_COUNT, N_EMBD)\n",
    "qkv = normalized_emb @ W_qkv              # (TOKEN_COUNT, 3 × N_EMBD)\n",
    "q, k, v = split(qkv)                      # each of shape (TOKEN_COUNT, N_EMBD)\n",
    "\n",
    "# Reshape to (TOKEN_COUNT, HEAD_COUNT, DIM_PER_HEAD) and transpose to (HEAD_COUNT, TOKEN_COUNT, DIM_PER_HEAD)\n",
    "q, k, v = transpose_heads(q, k, v)\n",
    "\n",
    "# Compute raw attention scores\n",
    "attn_weight[h, t, j] = sum over d of q[h, t, d] * k[h, j, d]\n",
    "\n",
    "# Apply causal attention mask\n",
    "attn_bias[t, j] = 0 if j ≤ t else −∞\n",
    "attn_weight += attn_bias\n",
    "\n",
    "# Normalize attention weights\n",
    "attn_weight = softmax(attn_weight)\n",
    "\n",
    "# Compute weighted value sum\n",
    "attn_output[h, t, d] = sum over j of attn_weight[h, t, j] * v[h, j, d]\n",
    "\n",
    "# Merge heads and apply output projection\n",
    "attn_output = merge_heads(attn_output)    # (TOKEN_COUNT, N_EMBD)\n",
    "attn_proj = attn_output @ W_c_proj        # (TOKEN_COUNT, N_EMBD)\n",
    "\n",
    "# Add residual connection\n",
    "self_attention_activations = normalized_emb + attn_proj            # (TOKEN_COUNT, N_EMBD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a9c54e",
   "metadata": {},
   "source": [
    "#### Feed-Forward Neural Network (MLP)\n",
    "\n",
    "The next step is the application of an MLP to the self-attention output. The input `self_attention_activations` to the MLP has shape `(TOKEN_COUNT, N_EMBD)`.\n",
    "\n",
    "We first apply LayerNorm to the input:\n",
    "\n",
    "$$\n",
    "\\texttt{self\\_attention\\_activations\\_norm}[t] = \\texttt{LayerNorm}(\\texttt{self\\_attention\\_activations}[t])\n",
    "$$\n",
    "\n",
    "We then apply a linear layer with weight matrix `W_1` of shape `(N_EMBD, MLP_MULT × N_EMBD)`, producing a tensor `h_1` of shape `(TOKEN_COUNT, MLP_MULT × N_EMBD)`. For each token position `t` and output dimension `k`, we compute:\n",
    "\n",
    "$$\n",
    "\\texttt{h\\_1}[t, k] = \\sum_{n=1}^{N\\_EMBD} \\texttt{self\\_attention\\_activations\\_norm}[t, n] \\cdot \\texttt{W\\_1}[n, k]\n",
    "$$\n",
    "\n",
    "We then apply the GELU activation function elementwise to `h_1`:\n",
    "\n",
    "$$\n",
    "\\texttt{h\\_1}[t, k] \\leftarrow \\text{GELU}(\\texttt{h\\_1}[t, k])\n",
    "$$\n",
    "\n",
    "The GELU activation is defined as:\n",
    "\n",
    "$$\n",
    "\\text{GELU}(x) = 0.5 \\cdot x \\cdot \\left(1 + \\tanh\\left(\\sqrt{\\frac{\\pi}{2}} \\cdot \\left(x + 0.044715 \\cdot x^3\\right)\\right)\\right)\n",
    "$$\n",
    "\n",
    "and [graphically looks like this](https://onlinelibrary.wiley.com/doi/10.1155/2023/4229924):\n",
    "\n",
    "<img src=\"inserted_images/gelu_graph.png\" width=500>\n",
    "\n",
    "\n",
    "We use [GELU](https://arxiv.org/abs/1606.08415) because it is differentiable everywhere, which helps with calculating gradients during training, and it has been shown to help Transformer models converge faster and achieve better performance.\n",
    "\n",
    "For inputs near zero, GELU acts like a probabilistic gate, outputting values near zero. For larger inputs, it behaves more like the identity function (for positives) or suppresses values entirely (for large negatives). This flexible behavior allows models to learn more nuanced representations and has been shown to improve performance in Transformer-based architectures.\n",
    "\n",
    "Next, we apply a second linear layer with weight matrix `W_2` of shape `(MLP_MULT × N_EMBD, N_EMBD)`, producing an output tensor `h_2` of shape `(TOKEN_COUNT, N_EMBD)`:\n",
    "\n",
    "$$\n",
    "\\texttt{h\\_2}[t, n] = \\sum_{k=1}^{MLP\\_MULT \\times N\\_EMBD} \\texttt{h\\_1}[t, k] \\cdot \\texttt{W\\_2}[k, n]\n",
    "$$\n",
    "\n",
    "Finally, we add a residual connection by summing the MLP output with the original input:\n",
    "\n",
    "$$\n",
    "\\texttt{mlp\\_activations}[t, n] = \\texttt{self\\_attention\\_activations}[t, n] + \\texttt{h\\_2}[t, n]\n",
    "$$\n",
    "\n",
    "This produces the final output of the MLP block with shape `(TOKEN_COUNT, N_EMBD)`.\n",
    "\n",
    "```python\n",
    "# Algorithm: MLP with GELU Activation and Residual\n",
    "self_attention_activations_norm = LayerNorm(self_attention_activations)         # Pre-MLP normalization\n",
    "h_1[t, k] = sum over n of self_attention_activations_norm[t, n] * W_1[n, k]\n",
    "h_1[t, k] = GELU(h_1[t, k]) for all t, k\n",
    "h_2[t, n] = sum over k of h_1[t, k] * W_2[k, n]\n",
    "mlp_activations[t, n] = self_attention_activations_norm[t, n] + h_2[t, n]       # Residual connection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63bec5d9",
   "metadata": {},
   "source": [
    "#### Linear Layer\n",
    "\n",
    "The linear layer takes in a tensor `mlp_activations` of shape `(TOKEN_COUNT, N_EMBD)`.\n",
    "\n",
    "Before applying the linear transformation, the model applies a final LayerNorm:\n",
    "\n",
    "$$\n",
    "\\texttt{mlp\\_activations\\_norm}[t] = \\texttt{LayerNorm}(\\texttt{mlp\\_activations}[t])\n",
    "$$\n",
    "\n",
    "This normalized tensor is then passed through a linear layer with weight matrix `W_vocab` of shape `(VOCAB_SIZE, N_EMBD)`.\n",
    "\n",
    "The linear layer computes logits, which represent unnormalized scores for each token in the vocabulary. The output tensor has shape `(TOKEN_COUNT, VOCAB_SIZE)`, where each row contains the logits for predicting the next token at that position in the sequence.\n",
    "\n",
    "Each output element is computed as:\n",
    "\n",
    "$$\n",
    "\\texttt{logits}[t, v] = \\sum_{n=1}^{N\\_EMBD} \\texttt{W\\_vocab}[v, n] \\cdot \\texttt{mlp\\_activations\\_norm}[t, n]\n",
    "$$\n",
    "\n",
    "During training, logits for all positions are used. During inference, only the logits at the final timestep are returned.\n",
    "\n",
    "```python\n",
    "# Algorithm: Linear Layer Transformation\n",
    "mlp_activations_norm = LayerNorm(mlp_activations)     # Final normalization\n",
    "logits[t, v] = sum over n of mlp_activations_norm[t, n] * W_vocab[v, n]\n",
    "if training:\n",
    "    return logits                                     # shape (TOKEN_COUNT, VOCAB_SIZE)\n",
    "else:\n",
    "    return logits[-1]                                 # shape (VOCAB_SIZE,)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043680ae",
   "metadata": {},
   "source": [
    "#### Generator\n",
    "\n",
    "The generator function takes as input a sequence `seq` of shape `(TOKEN_COUNT)` and a target number `M` indicating how many new tokens to generate. It iteratively appends tokens to the sequence by performing a forward pass and sampling the next token from the model’s output.\n",
    "\n",
    "The process is repeated for `M` steps. In each step, the sequence is trimmed if necessary to ensure that its length does not exceed the model's `block_size`. A forward pass through the model produces logits, which are converted to probabilities using softmax. A new token is then sampled from this distribution and appended to the sequence.\n",
    "\n",
    "```python\n",
    "# Algorithm: Generator – Token Generation\n",
    "for step in range(M):\n",
    "    trimmed_seq = seq[-BLOCK_SIZE:]                     # Trim sequence if needed\n",
    "    logits = model(trimmed_seq)                         # Forward pass → shape (TOKEN_COUNT, VOCAB_SIZE)\n",
    "    last_logits = logits[-1]                            # Take logits at last timestep → shape (VOCAB_SIZE,)\n",
    "    probs = softmax(last_logits)                        # Convert to probabilities\n",
    "    new_token = sample_from(probs)                      # Sample next token\n",
    "    seq = append(seq, new_token)                        # Add token to sequence\n",
    "return seq                                              # Final sequence after M steps\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4bcae4",
   "metadata": {},
   "source": [
    "#### Full Steps from Input to Output\n",
    "\n",
    "Here, we show a diagram and summarize the entire sequence from input to output:\n",
    "\n",
    "<img src=\"inserted_images/model_arch.png\" width=500>\n",
    "\n",
    "```python\n",
    "# Step 1: Input\n",
    "# Input: tensor x of shape (TOKEN_COUNT)\n",
    "x = input_tensor\n",
    "\n",
    "# Step 2: Embeddings\n",
    "tok_emb = TokenEmbedding(x, W_e)                                     # Token embeddings → shape (TOKEN_COUNT, N_EMBD)\n",
    "pos_emb = PositionEmbedding(T, W_p)                                  # Position embeddings → shape (TOKEN_COUNT, N_EMBD)\n",
    "emb = tok_emb + pos_emb                                              # Combined embeddings → shape (TOKEN_COUNT, N_EMBD)\n",
    "activations = emb\n",
    "# Step 3: Apply Transformer Blocks\n",
    "for layer in range(LAYER_COUNT):\n",
    "\n",
    "    # LayerNorm + Self-Attention\n",
    "    activations_norm = LayerNorm(activations)\n",
    "    residual = activations_norm                                      # Store input for the residual connection\n",
    "    qkv = activations_norm @ W_qkv                                   # Project to Q, K, V → (TOKEN_COUNT, 3 × N_EMBD)\n",
    "    q, k, v = split(qkv)                                             # (TOKEN_COUNT, N_EMBD) each\n",
    "    q, k, v = transpose_heads(q, k, v)                               # (HEAD_COUNT, TOKEN_COUNT, DIM_PER_HEAD)\n",
    "    attn_weight = dot(q, k) + attn_bias                              # (HEAD_COUNT, TOKEN_COUNT, TOKEN_COUNT)\n",
    "    attn_weight = softmax(attn_weight)\n",
    "    attn_output = weighted_sum(attn_weight, v)                       # (HEAD_COUNT, TOKEN_COUNT, DIM_PER_HEAD)\n",
    "    attn_output = merge_heads(attn_output)                           # (TOKEN_COUNT, N_EMBD)\n",
    "    attn_proj = attn_output @ W_c_proj                               # Output projection\n",
    "    activations = residual + attn_proj                               # Residual connection\n",
    "\n",
    "    # LayerNorm + MLP\n",
    "    self_attention_activations = activations\n",
    "    residual = self_attention_activations                            # Store input for the residual connection\n",
    "    self_attention_activations_norm = LayerNorm(self_attention_activations)\n",
    "    h_1 = self_attention_activations_norm @ W_1                      # First linear → (TOKEN_COUNT, MLP_MULT × N_EMBD)\n",
    "    h_1 = GELU(h_1)                                                  # Activation\n",
    "    h_2 = h_1 @ W_2                                                  # Second linear → (TOKEN_COUNT, N_EMBD)\n",
    "    mlp_activations = residual + h_2                                 # Residual connection\n",
    "\n",
    "# Step 4: Final LayerNorm\n",
    "mlp_activations_norm = LayerNorm(mlp_activations)                    # (TOKEN_COUNT, N_EMBD)\n",
    "\n",
    "# Step 5: Output projection (to vocabulary)\n",
    "logits = mlp_activations_norm @ W_vocab                              # shape (TOKEN_COUNT, VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6b3a2d",
   "metadata": {},
   "source": [
    "### 2. Parameter Allocation Experiments\n",
    "\n",
    "As discussed earlier, we initialize a GPT model by specifying the number of attention heads, transformer blocks, and the embedding dimension. Increasing the number of transformer blocks (`n_layer`) and the size of the embedding dimension (`n_embd`) increases the total number of parameters in the model. This introduces a tradeoff: larger models tend to be more capable, but they also take longer to train.\n",
    "\n",
    "We were interested in understanding the best way to allocate a fixed budget of parameters. In other words, if we can afford a model with roughly *n* parameters, how should we distribute those parameters across layers and embedding dimensions to get the best performance?\n",
    "\n",
    "To explore this, we compared models with `n_layer = 1, 2, 3, or 4` transformer blocks. For each model, we adjusted the embedding dimension so that the total parameter count remained similar. All models used a single attention head (`n_head = 1`) for consistency. The table below shows the architectures we tested:\n",
    "\n",
    "| `n_layer` | `n_embd` | Total Parameters |\n",
    "|-----------|----------|------------------|\n",
    "| 1         | 24       | 7,248            |\n",
    "| 2         | 17       | 7,208            |\n",
    "| 3         | 14       | 7,308            |\n",
    "| 4         | 12       | 7,152            |\n",
    "\n",
    "For reference, the original minimal model used throughout this report has `n_layer = 1`, `n_embd = 12`, and 1,896 parameters, so all of these architectures are substantially larger and more complex.\n",
    "\n",
    "We conducted 15 training trials for each architecture, training for 100,000 iterations per run. Below are the average training curves:\n",
    "\n",
    "<img src=\"inserted_images/diff_layer_runs.png\" width=500>\n",
    "\n",
    "What can we conclude from this experiment? Honestly, not much. All of these models are more powerful than the minimal configuration we already knew could learn the task, so it’s not surprising that they all succeeded. And, because adding more transformer blocks increases the depth of the function the model needs to learn, it's also unsurprising that deeper models converged more slowly. This experiment might be more informative in the context of a harder task where models are not all guaranteed to succeed, and where differences in generalization or learning speed could be more meaningful. In that setting, parameter allocation might have a clearer impact on final performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e770ad3",
   "metadata": {},
   "source": [
    "### 3. Probing a Multi-Headed Model\n",
    "\n",
    "#### Motivation\n",
    "\n",
    "We previously identified two core rules of tic-tac-toe and observed that a single-headed model often learned them in two distinct phases. This led us to wonder what would happen if we give the model a second attention head? Could each head specialize in a different rule, eliminating the staggered learning pattern?\n",
    "\n",
    "To explore this, we trained a model with `n_layer = 1`, `n_head = 2`, and `n_embd = 12`, a setup which yielded the same number of parameters as the original, one-headed model. We ran 20 training trials, training for 100,000 iterations, and 80% of runs converged. Take a look at all of the converging two-headed training runs below:\n",
    "\n",
    "<img src=\"inserted_images/converging_2_heads.png\" width=500>\n",
    "\n",
    "Overall, there seems to be less of a pattern in this training than there was when we trained the original model. Only one of these training trials stalled with a validation loss between 1.36 and 1.37, where we saw stalling occur before, and there does not seem to be a new consistent place where training does stall. In contrast, many of the training runs look relatively smooth and converge quickly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc50793",
   "metadata": {},
   "source": [
    "#### Setup\n",
    "\n",
    "Based on these trends, we suspected that the two-headed model might be training in a fundamentally different way. The training run we took data from seemed typical for this new architecture and is shown below,:\n",
    "\n",
    "<img src=\"inserted_images/probing_trial_2h.png\" width=500>\n",
    "\n",
    "We saved checkpoints at the same stages as with the one-headed model:\n",
    "\n",
    "- Random start\n",
    "- After loss dropped below 1.37 (\"Stalling Begins\" checkpoint)\n",
    "- After loss dropped below 1.36 (\"Stalling Ends\" checkpoint)\n",
    "- Fully trained\n",
    "\n",
    "We then followed the same probing procedure, training three probes (Linear, Small MLP, and Large MLP) to use the model's activations to predict the Space Occupancy and Win Detection tasks. If our hypothesis was true and each head did learn a different rule, what might we expect? We thought we might notice the following:\n",
    "\n",
    "1. **No fundamental change between Stalling Begins and Stalling Ends checkpoints**  \n",
    "   In the one-headed model, the transition between these checkpoints came with a large change in probe performance as the model started to learn to detect a winner. However, if each head now learns its rule independently, we wouldn't expect such a major shift in internal representation, especially at the same place where it happened originally.\n",
    "\n",
    "2. **Space Occupancy and Win Detection being learned together.**  \n",
    "   With shared responsibility, both tasks should improve at the same time throughout training. We’re not expecting a staged progression where one rule is represented before another anymore, but rather steady improvement as the model gets better overall.\n",
    "\n",
    "3. **Head-level specialization in probe results.**  \n",
    "   If heads divide up the rules, then probing individual head outputs should show one head consistently better at Space Occupancy and the other at Win Detection, corresponding to the rules they represent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126b0b3b",
   "metadata": {},
   "source": [
    "#### Full Model Probing\n",
    "\n",
    "We first explore how the model's representations evolve across checkpoints, hoping to answer our first two questions. Probes were trained on activations taken after the final LayerNorm, using the same setup as in the one-headed case. Results are shown in both table and graphical form below:\n",
    "\n",
    "#### Linear Probe\n",
    "\n",
    "| Task              | Random | Stalling Begins | Stalling Ends | Fully Trained |\n",
    "|------------------|--------|------------------|----------------|----------------|\n",
    "| Space Occupancy  | 0.658  | 0.909            | 0.907          | 0.954          |\n",
    "| Win Detection | 0.905  | 0.966            | 0.966          | 0.969          |\n",
    "\n",
    "#### Small MLP Probe\n",
    "\n",
    "| Task              | Random | Stalling Begins | Stalling Ends | Fully Trained |\n",
    "|------------------|--------|------------------|----------------|----------------|\n",
    "| Space Occupancy  | 0.790  | 0.954            | 0.954          | 0.972          |\n",
    "| Win Detection | 0.925  | 0.988            | 0.988          | 0.988          |\n",
    "\n",
    "#### Large MLP Probe\n",
    "\n",
    "| Task              | Random | Stalling Begins | Stalling Ends | Fully Trained |\n",
    "|------------------|--------|------------------|----------------|----------------|\n",
    "| Space Occupancy  | 0.837  | 0.977            | 0.977          | 0.980          |\n",
    "| Win Detection | 0.925  | 0.989            | 0.990          | 0.990          |\n",
    "\n",
    "\n",
    "#### Results Plotted\n",
    "\n",
    "<img src=\"inserted_images/two_head_by_ckpt.png\" width=600>\n",
    "\n",
    "At the final checkpoint, probe performance is comparable to that seen with the original one-headed model. This suggests that architectural changes didn’t affect the model’s capacity to form accurate internal representations. \n",
    "\n",
    "The loss curve gave no indication of a major shift between the second and third checkpoints, and the probe results confirm this intuition. For all probe types and tasks, probe performances at these checkpoints are nearly identical. \n",
    "\n",
    "Both tasks are learned well, though Win Detection appears to be picked up slightly earlier. Still, Space Occupancy continues to improve steadily through to the end of training. This suggests that both internal representations are learned simultaneously, albeit at slightly different rates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2029d37f",
   "metadata": {},
   "source": [
    "#### Probing Individual Heads\n",
    "\n",
    "We also captured activations from inside the transformer block before the outputs of the two attention heads were combined, and separated these activations into those coming from Head 0 and Head 1. If each head were learning a distinct rule, we’d expect a clear pattern of specialization: probes trained on Head 0’s activations would perform well on one task, and probes on Head 1’s activations would perform well on the other. The results of this experiment are shown below:\n",
    "\n",
    "<p float=\"left\">\n",
    "  <img src=\"inserted_images/so_two_head.png\" width=\"400\" />\n",
    "  <img src=\"inserted_images/wd_two_head.png\" width=\"400\" />\n",
    "</p>\n",
    "\n",
    "As expected, these probe accuracies are lower than those trained on full activations. This is because when we isolate a single head from a two-headed model, we remove half of the activations the model would otherwise use.\n",
    "\n",
    "For Space Occupancy, probes trained on Head 1’s activations consistently outperform those trained on Head 0’s, across all checkpoints, including the randomly initialized one. This early gap might be due to lucky initialization, but it holds throughout training. By the end, the Head 1 probe reaches high accuracy, suggesting that Head 1 plays a dominant role in representing this rule.\n",
    "\n",
    "Win Detection shows less clear contrast between probes. Between the Stalling Begins and Stalling Ends checkpoints, probes trained on Head 1’s activations perform better than those from Head 0, suggesting it initially captures this structure more effectively as well. By the Fully Trained checkpoint, however, Head 1’s probe performance actually declines, and both heads yield similar results. This suggests that Win Detection representation is done with both heads contributing, rather than with one head specializing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647a7ebb",
   "metadata": {},
   "source": [
    "#### Takeaways\n",
    "\n",
    "The two-headed model clearly learns differently from the one-headed version. Both Space Occupancy and Win Detection are learned simultaneously with no major shift between the Stalling Begins and Stalling Ends checkpoints. There’s steady improvement on both tasks throughout training, not a pattern where one task is learned completely before learning on the other starts.\n",
    "\n",
    "We do see some signs of specialization: Probes trained Head 1 handle the Space Occupancy much better than probes trained on Head 0. For Win Detection, though, both heads contribute, and neither clearly dominates. We also observe a strange pattern where probes trained on Head 1 are strong at this task early in training, but get weaker by the time training ends.\n",
    "\n",
    "We couldn’t fully identify the roles of each head or state definitively how the two-headed model trains, as the results we observe are unintuitive, and very interesting. This could definitely be a path for future research, but I unfortunately ran out of time before my thesis was due."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c684e90",
   "metadata": {},
   "source": [
    "## 9. References\n",
    "\n",
    "1. **Alain, G., & Bengio, Y.** (2016). *Understanding intermediate layers using linear classifier probes*. arXiv preprint [arXiv:1610.01644](https://arxiv.org/abs/1610.01644)\n",
    "\n",
    "2. **Haeusler, P.** (2023). *Tic Tac Transformer*. Personal website. [https://philliphaeusler.com/posts/tic_tac_toe/](https://philliphaeusler.com/posts/tic_tac_toe/)\n",
    "\n",
    "3. **Hendrycks, D., & Gimpel, K.** (2016). *Gaussian Error Linear Units (GELUs)*. arXiv preprint [arXiv:1606.08415](https://arxiv.org/abs/1606.08415)\n",
    "\n",
    "4. **Hsu, W.-Y., Ko, C.-L., Chen, J.-C., Wei, T.-H., Hsueh, C.-H., & Wu, I.-C.** (2020). *On solving the 7,7,5-game and the 8,8,5-game*. *Theoretical Computer Science*, 816, 75–90. [https://doi.org/10.1016/j.tcs.2020.02.023](https://doi.org/10.1016/j.tcs.2020.02.023)\n",
    "\n",
    "5. **Karpathy, A.** (2023). *Let's build GPT: from scratch, in code, spelled out*. YouTube. [https://www.youtube.com/watch?v=kCc8FmEb1nY](https://www.youtube.com/watch?v=kCc8FmEb1nY)\n",
    "\n",
    "6. **Lee, M.** (2023). *Mathematical Analysis and Performance Evaluation of the GELU Activation Function in Deep Learning*. *Mathematical Problems in Engineering*. [https://onlinelibrary.wiley.com/doi/10.1155/2023/4229924](https://onlinelibrary.wiley.com/doi/10.1155/2023/4229924)\n",
    "\n",
    "7. **Li, K., Hopkins, A. K., Bau, D., Viégas, F., Pfister, H., & Wattenberg, M.** (2022). *Emergent World Representations: Exploring a Sequence Model Trained on a Synthetic Task*. arXiv preprint [arXiv:2210.13382](https://arxiv.org/abs/2210.13382)\n",
    "\n",
    "8. **Nanda, N.** (2023). *Actually, Othello-GPT Has A Linear Emergent World Representation*. Blog post. [https://www.neelnanda.io/mechanistic-interpretability/othello](https://www.neelnanda.io/mechanistic-interpretability/othello)\n",
    "\n",
    "9. **Vaswani, A., et al.** (2017). *Attention Is All You Need*. *Advances in Neural Information Processing Systems*, 30. [https://arxiv.org/abs/1706.03762](https://arxiv.org/abs/1706.03762)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
